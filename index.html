<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="LLM-as-a-Coauthor: Can Mixed Human-Written and Machine-Generated Text Be Detected?">
  <meta name="keywords" content="Machine Generated Text, MGT Detector, Human Computer Interaction">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>LLM-as-a-Coauthor: Can Mixed Human-Written and Machine-Generated Text Be Detected?</title>
  <script type="module" src="https://md-block.verou.me/md-block.js"></script>


  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">

  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./img/gui-logo.jpg">

  <link rel="stylesheet" href="./stylesheets/layout.css">
  <link rel="stylesheet" href="./stylesheets/index.css">
  <link rel="stylesheet" href="./bowe_componets/css/bootstrap.table.min.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <link href="./static/css/controls.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="./static/css/custom.css" media="screen" rel="stylesheet" type="text/css" />
</head>

<body>

  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
    <div class="navbar-menu">
      <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
        <a class="navbar-item" href="https://dongping-chen.github.io/">
          <span class="icon">
            <i class="fas fa-home"></i>
          </span>
        </a>

        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link">
            More Research
          </a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://gui-world.github.io/">
              GUI-World üñ•Ô∏èüìä
            </a>
            <a class="navbar-item" href="https://mllm-judge.github.io">
              MLLM-as-a-Judge ‚öñÔ∏èüßë‚Äç‚öñÔ∏è
            </a>
            <a class="navbar-item" href="https://unigen-framework.github.io/unigen-framework/#">
              UniGen üåêüìù
            </a>
            <a class="navbar-item" href="https://github.com/Flossiee/HonestyLLM">
              HonestyLLM üßë‚Äç‚öñÔ∏èü§ñ
            </a>
            <a class="navbar-item" href="https://trustllmbenchmark.github.io/TrustLLM-Website/">
              TrustLLM üîíü§ñ
            </a>
          </div>
        </div>
      </div>

    </div>
  </nav>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              LLM-as-a-Coauthor: Can Mixed Human-Written and Machine-Generated Text Be Detected?
            </h1>
            <div class="is-size-5 publication-authors">
              <b>NAACL 2024</b>
            </div>
            <div class="is-size-5 publication-authors">
              <span class="author-block"><a href="https://mask-hui.github.io/">Qihui Zhang</a><sup
                  style="color:#ec8bfd;">1</sup><sup style="color:#ff2b67;">*</sup>,</span>
              <span class="author-block"><a href="https://flossiee.github.io/">Chujie Gao</a><sup
                  style="color:#ec8bfd;">1</sup><sup style="color:#ff2b67;">*</sup>,</span>
              <span class="author-block"><a href="https://dongping-chen.github.io/">Dongping Chen</a><sup
                  style="color:#ec8bfd;">1</sup><sup style="color:#ff2b67;">*</sup>,</span>
              <span class="author-block"><a href="https://howiehwong.github.io/">Yue Huang</a><sup
                  style="color:#2bff32;">2</sup>,</span>
              <span class="author-block">Yixin Huang<sup style="color:#fabb55;">3</sup>,</span>
              <span class="author-block">Zhenyang Sun<sup style="color:#ec8bfd;">1</sup>,</span>
              <span class="author-block">Shilin Zhang<sup style="color:#ec8bfd;">1</sup>,</span>
              <span class="author-block">Weiye Li<sup style="color:#ec8bfd;">1</sup>,</span>
              <span class="author-block">Zhengyan Fu<sup style="color:#ec8bfd;">1</sup>,</span>
              <span class="author-block"><a href="http://wanyao.me/"><b>Yao Wan</b></a><sup
                  style="color:#ec8bfd;">1</sup>,</span>
              <span class="author-block"><a href="https://lichao-sun.github.io/"><b>Lichao Sun</b></a><sup
                  style="color:#66f1fb;">4</sup></span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup style="color:#ec8bfd;">1</sup>Huazhong University of Science and
                Technology,</span>
              <br>
              <span class="author-block"><sup style="color:#2bff32;">2</sup>University of Notre Dame,</span>
              <span class="author-block"><sup style="color:#fabb55;">3</sup>
                Institut Polytechnique de Paris,</span>
              <span class="author-block"><sup style="color:#66f1fb;">4</sup>Lehigh University</span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">{<a href="mailto:maskhui1003@gmail.com">maskhui1003</a>, <a
                  href="mailto:gaochujie1107@gmail.com">gaochujie1107</a>, <a
                  href="mailto:dongpingchen0612@gmail.com">dongpingchen0612</a>}@gmail.com</span>
            </div>


            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <!--                <span class="link-block">-->
                <!--                  <a href="https://arxiv.org/pdf/2011.12948" class="external-link button is-normal is-rounded is-dark">-->
                <!--                    <span class="icon">-->
                <!--                      <i class="fas fa-file-pdf"></i>-->
                <!--                    </span>-->
                <!--                    <span>Paper</span>-->
                <!--                  </a>-->
                <!--                </span>-->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2401.05952" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/Dongping-Chen/MixSet"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- Dataset Link. -->
                <span class="link-block">
                  <a href="https://huggingface.co/datasets/shuaishuaicdp/MixSet"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="far fa-images"></i>
                    </span>
                    <span>Data</span>
                  </a>
                </span>
                <!-- Data Viewer. -->
                <!-- <span class="link-block">
                  <a href="https://huggingface.co/shuaishuaicdp/GUI-Vid" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fa fa-desktop"></i>
                    </span>
                    <span>Model</span>
                  </a>
                </span> -->
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- <section class="section">
    <div class="container is-max-desktop">
      <div class="column is-full">
        <video controls muted loop autoplay width="100%">
          <source src="static/videos/main.mp4" type="video/mp4">
        </video>
      </div>
    </div>
  </section> -->

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Main Figure. -->
      <h1 class="title">Introduction</h1>
      <div class="content has-text-justified">
        <img src="img/llm-coauthor-overview.png" width="54%" alt="llm-coauthor Overview" class="responsive-image">
        <img src="img/llm-coauthor-radar.png" width="45%" alt="llm-coauthor radar" class="responsive-image">
        <md-block>
          In this work, we define mixtext, a form of mixed text involving both AI
          and human-generated content. Then, we introduce **MixSet**, the first dataset dedicated to
          studying these mixtext scenarios. Leveraging **MixSet**, we executed comprehensive experiments to assess the
          efficacy of prevalent MGT
          detectors in handling mixtext situations, evaluating their performance in terms of effectiveness,
          robustness, and generalization.
          <ol>
            <li><b>New Definitions to Mixture of MGT and HWT.</b> We defined mixtext, a form of mixed text involving
              both AI and human-generated content, providing a new perspective for further exploration
              in related fields. </li>
            <li><b>A Novel Dataset.</b> We proposed a new dataset **MixSet**, which
              specifically addresses the mixture of MGT and
              HWT, encompassing a diverse range of operations within real-world scenarios, addressing
              gaps in previous research. </li>
            <li><b>Comprehensive Experiments and Valuable Insights.</b> Based on <b>MixSet</b>, we conducted extensive
              experiments involving mainstream detectors and
              obtained numerous insightful findings, which
              provide a strong impetus for future research.</li>
          </ol>
        </md-block>
      </div>
      <!--/ Main Figure. -->
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-wdith">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <md-block>
              With the rapid development and widespread application of Large Language Models (LLMs),
              the use of Machine-Generated Text (MGT) has
              become increasingly common, bringing with
              it potential risks, especially in terms of quality
              and integrity in fields like news, education, and
              science. Current research mainly focuses on
              purely MGT detection without adequately addressing mixed scenarios, including AI-revised
              Human-Written Text (HWT) or human-revised
              MGT. To tackle this challenge, we define mixtext, a form of mixed text involving both AI
              and human-generated content. Then, we introduce **MixSet**, the first dataset dedicated to
              studying these mixtext scenarios. Leveraging
              **MixSet**, we executed comprehensive experiments to assess the efficacy of prevalent MGT
              detectors in handling mixtext situations, evaluating their performance in terms of effectiveness,
              robustness, and generalization. Our findings
              reveal that existing detectors struggle to identify mixtext, particularly in dealing with subtle
              modifications and style adaptability. This research underscores the urgent need for more
              fine-grain detectors tailored for mixtext, offering valuable insights for future research.
            </md-block>
          </div>
        </div>
      </div>
      <!--/ Abstract. -->
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Environment Infrastructure. -->
      <h2 class="title is-3">MixSet Dataset Construction</h2>
      <div class="content has-text-justified">
        <img src="img/llm-coauthor-construction.png" width="100%" alt="environment infrastructure"
          class="responsive-image">
        <md-block>In this section, we present **MixSet** (**Mix**case
          Data**set**), the first dataset featuring a blend of HWT
          and MGT. Distinguished from earlier datasets
          exclusively composed of pure HWT and MGT,
          **MixSet** comprises a total of 3,600 mixtext instances, and the pipeline of its construction is
          shown in Figure 3. These operations are grounded
          in real-world application scenarios, each altered
          by a single LLM or through manual intervention,
          contributing 300 instances in our **MixSet**.
        </md-block>
        <md-block>
          For our base data, we meticulously select pure
          HWT and MGT datasets. In the case of HWT,
          we gather datasets proposed before the widespread
          use of LLMs to mitigate potential contamination
          by MGT, as detailed in Table 1. For MGT, we
          choose samples from previous datasets,
          generated in a QA pattern by different LLMs, including the GPT family,
          ChatGLM, BloomZ, Dolly 4
          , and StableLM, all distinct from our **MixSet** instances.
        </md-block>
        <div class="cover" id="contentCover">
                <div class="infoCard">
                  <div class="infoBody">
                    <div class="tabs is-centered example_lst">
                      <ul>
                        <li class="is-active"><a title="Original Sources">Original Sources</a></li>
                        <li><a title="Operations">Operations</a></li>
                        <li><a title="Operation Details">Operation Details</a></li>
                        <li><a title="Size">Size</a></li>
                        <li><a title="Metric Analysis">Metric Analysis</a></li>
                      </ul>

                    </div>
                    <script type="text/javascript">
                      document.querySelectorAll(".example_lst li").forEach(e => {
                        e.addEventListener("click", Click_1)
                      })

                      function Click_1(eve) {
                        const iTxt = eve.srcElement.innerText
                        for (let v of document.querySelectorAll(".example_lst a")) {
                          if (iTxt === v.innerText) {
                            v.parentElement.className = "is-active";
                          } else {
                            v.parentElement.className = "";
                          }
                        }
                        for (let block of document.getElementsByClassName('lib_examples')) {
                          block.style.display = (block.title === iTxt) ? 'block' : 'none';
                        }
                      }

                    </script>
                    <div title="Original Sources" class="lib_examples" id="BoardPanel1" style="display: block;">

                      <md-block>
                        The original resources of Human Written Texts
                        in constructing our <b>MixSet</b>.
                      </md-block>
                      <img src="img/llm-coauthor-statistic1.png" width="100%" alt="environment infrastructure"
                        class="responsive-image">


                    </div>

                    <div title="Operations" class="lib_examples" id="BoardPanel3" style="display: none;">

                      <md-block>
                        Different operations with their operation levels.
                        ‚úî demonstrate that <b>MixSet</b> contains a subset operates
                        at that level.

                      </md-block>
                      <img src="img/llm-coauthor-statistic2.png" width="100%" alt="environment infrastructure"
                        class="responsive-image">

                    </div>

                    <div title="Operation Details" class="lib_examples" id="BoardPanel3" style="display: none;">

                      <p>Combined with previous studies and real scenarios, we use
                        five operations to generate mixtexts. They are divided into two operations: <b>1) AI-revised:</b> it contains three operations including ‚Äòpolish‚Äô, ‚Äòcomplete‚Äô, and ‚Äòrewrite‚Äô. <b>2) Human-revised:</b>
                        it includes ‚Äòadapt‚Äô and ‚Äòhumanize‚Äô.</p>
                        <ol>
                          <li><b>Polish.</b> Polish operation contains
                            token-level and sentence-level polishing. Token-level makes alterations at the individual word
                            level, including changes such as adjusting words
                            for precision or correcting spelling errors. On
                            the other hand, sentence-level aims to enhance
                            the overall coherence and clarity of the text by
                            revising and restructuring the complete sentence.</li>
                            <li><b>Complete.</b> Complete operation involves taking 1/3 of every text and employing LLMs to generate the rest of the text.
                            </li>
                            <li><b>Rewrite.</b> Rewrite operation requires LLMs to initially comprehend and extract
                              key information from the given HWT and then
                              rewrite them.</li>
                              <li><b>Humanize.</b> Humanize operation typically refers to the modification of MGT
                                to more closely mimic the natural noise for LLM
                                that human writing always
                                brings. We employed LLMs to introduce various
                                perturbations to the pure MGT, including <i>typo,
                                grammatical mistakes, links, and tags.</i></li>
                              <li><b>Adapt.</b> Adapt operation refers
                                to modifying MGT to ensure its alignment to fluency and naturalness to human linguistic habits
                                without introducing any error expression. The
                                adapt operation is also divided into token-level
                                and sentence-level adaptation. We accordingly
                                performed manual annotations on the pure MGT
                                dataset at both the token and sentence levels.</li>
                        </ol>

                    </div>

                    <div title="Size" class="lib_examples" id="BoardPanel4" style="display: none;">

                      <md-block>
                        Detailed distribution of different operations in <b>MixSet</b>.
                      </md-block>
                      <img src="img/llm-coauthor-statistic3.png" width="100%" alt="environment infrastructure"
                        class="responsive-image">
                    </div>

                    <div title="Metric Analysis" class="lib_examples" id="BoardPanel4" style="display: none;">
                      <md-block>

                      </md-block>
                      <img src="img/llm-coauthor-statistic4.png" width="100%" alt="environment infrastructure"
                        class="responsive-image">
                    </div>
                  </div>
                </div>
        </div>
      </div>
      <!--/ Environment Infrastructure. -->
    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Experiment Setups</h2>
      <div class="content has-text-justified">
        <p><b>Class Number.</b> In real-world scenarios, people often aim to detect the presence of MGT in the text
          (e.g., spreading fake news or propaganda, reinforcing and intensifying prejudices), and sometimes mixtext is
          also treated as MGT (e.g., student modified some words in MGT (i.e., mixtext) to generate homework, to avoid
          detection). Therefore, our experiments established two categorization systems: binary and three-class. In the
          binary classification, mixtext is categorized as MGT, while in the three-class classification, mixtext is
          treated as a separate class.</p>

        <div class="cover" id="contentCover">
                <div class="infoCard">
                  <div class="infoBody">
                    <div class="tabs is-centered example_lst">
                      <ul>
                        <li><a title="Detectors">Detectors</a></li>
                        <li class="is-active"><a title="Metrics">Metrics</a></li>
                        <li><a title="Train/Test Split">Train/Test Split</a></li>
                      </ul>

                    </div>
                    <script type="text/javascript">
                      document.querySelectorAll(".example_lst li").forEach(e => {
                        e.addEventListener("click", Click_1)
                      })

                      function Click_1(eve) {
                        const iTxt = eve.srcElement.innerText
                        for (let v of document.querySelectorAll(".example_lst a")) {
                          if (iTxt === v.innerText) {
                            v.parentElement.className = "is-active";
                          } else {
                            v.parentElement.className = "";
                          }
                        }
                        for (let block of document.getElementsByClassName('lib_examples')) {
                          block.style.display = (block.title === iTxt) ? 'block' : 'none';
                        }
                      }

                    </script>
                    <div title="Detectors" class="lib_examples" id="BoardPanel1" style="display: none;">
                      <!-- <div class="content has-text-justified"> -->
                      <md-block>
                        Detectors used in different experiments.
                      </md-block>
                      <!-- </div> -->
                      <div class="table-container">
                        <table>
                          <thead>
                            <tr>
                              <th>Detector</th>
                              <th>Q 1</th>
                              <th>Q 2</th>
                              <th>Q 3</th>
                              <th>Q 4</th>
                            </tr>
                          </thead>
                          <tbody>
                            <tr>
                              <td>Log-likelihood</td>
                              <td>‚úîÔ∏è</td>
                              <td>‚úîÔ∏è</td>
                              <td>‚úñÔ∏è</td>
                              <td>‚úîÔ∏è</td>
                            </tr>
                            <tr>
                              <td>Entropy</td>
                              <td>‚úîÔ∏è</td>
                              <td>‚úîÔ∏è</td>
                              <td>‚úñÔ∏è</td>
                              <td>‚úñÔ∏è</td>
                            </tr>
                            <tr>
                              <td>GLTR</td>
                              <td>‚úîÔ∏è</td>
                              <td>‚úîÔ∏è</td>
                              <td>‚úñÔ∏è</td>
                              <td>‚úñÔ∏è</td>
                            </tr>
                            <tr>
                              <td>Log-rank</td>
                              <td>‚úîÔ∏è</td>
                              <td>‚úîÔ∏è</td>
                              <td>‚úñÔ∏è</td>
                              <td>‚úñÔ∏è</td>
                            </tr>
                            <tr>
                              <td>DetectGPT</td>
                              <td>‚úîÔ∏è</td>
                              <td>‚úîÔ∏è</td>
                              <td>‚úîÔ∏è</td>
                              <td>‚úîÔ∏è</td>
                            </tr>
                            <tr>
                              <td>Radar</td>
                              <td>‚úîÔ∏è</td>
                              <td>‚úîÔ∏è</td>
                              <td>‚úñÔ∏è</td>
                              <td>‚úñÔ∏è</td>
                            </tr>
                            <tr>
                              <td>ChatGPT Detector</td>
                              <td>‚úîÔ∏è</td>
                              <td>‚úîÔ∏è</td>
                              <td>‚úîÔ∏è</td>
                              <td>‚úîÔ∏è</td>
                            </tr>
                            <tr>
                              <td>DistillBert</td>
                              <td>‚úîÔ∏è</td>
                              <td>‚úîÔ∏è</td>
                              <td>‚úîÔ∏è</td>
                              <td>‚úñÔ∏è</td>
                            </tr>
                            <tr>
                              <td>GPT-sentinel</td>
                              <td>‚úîÔ∏è</td>
                              <td>‚úîÔ∏è</td>
                              <td>‚úñÔ∏è</td>
                              <td>‚úñÔ∏è</td>
                            </tr>
                            <tr>
                              <td>OpenAI Classifier</td>
                              <td>‚úîÔ∏è</td>
                              <td>‚úñÔ∏è</td>
                              <td>‚úñÔ∏è</td>
                              <td>‚úñÔ∏è</td>
                            </tr>
                            <tr>
                              <td>Ghostbuster</td>
                              <td>‚úîÔ∏è</td>
                              <td>‚úñÔ∏è</td>
                              <td>‚úñÔ∏è</td>
                              <td>‚úñÔ∏è</td>
                            </tr>
                            <tr>
                              <td>GPTZero</td>
                              <td>‚úîÔ∏è</td>
                              <td>‚úñÔ∏è</td>
                              <td>‚úñÔ∏è</td>
                              <td>‚úñÔ∏è</td>
                            </tr>
                          </tbody>
                        </table>
                      </div>

                    </div>

                    <div title="Metrics" class="lib_examples" id="BoardPanel2" style="display: block;">
                      <!-- <div class="content has-text-justified"> -->
                      <md-block>
                        The details of class number, metrics, and
                        whether the detectors are retrained in our experiments.
                        Except for Question 2(b), we implement binary classifications i.e., HWT and MGT. Per. stands for
                        Percentage.
                      </md-block>
                      <!-- </div> -->

                      <div class="table-container">
                        <table>
                          <thead>
                            <tr>
                              <th rowspan="2">Setting</th>
                              <th rowspan="2">Q 1</th>
                              <th colspan="2">Q 2</th>
                              <th rowspan="2">Q 3</th>
                              <th rowspan="2">Q 4</th>
                            </tr>
                            <tr>
                              <th>(a)</th>
                              <th>(b)</th>
                            </tr>
                          </thead>
                          <tbody>
                            <tr>
                              <td class="bold">Class Num.</td>
                              <td>2-Class</td>
                              <td>2-Class</td>
                              <td>3-Class</td>
                              <td>2-Class</td>
                              <td>2-Class</td>
                            </tr>
                            <tr>
                              <td class="bold">Metric</td>
                              <td>MGT Per.</td>
                              <td>F1, AUC</td>
                              <td>F1</td>
                              <td>AUC</td>
                              <td>F1, AUC</td>
                            </tr>
                            <tr>
                              <td class="bold">Retrained?</td>
                              <td>‚úñÔ∏è</td>
                              <td>‚úîÔ∏è</td>
                              <td>‚úîÔ∏è</td>
                              <td>‚úîÔ∏è</td>
                              <td>‚úîÔ∏è</td>
                            </tr>
                          </tbody>
                        </table>
                      </div>
                    </div>

                    <div title="Train/Test Split" class="lib_examples" id="BoardPanel2" style="display: none;">
                      <!-- <div class="content has-text-justified"> -->
                      <md-block>
                        An outline of detailed training set construction
                        for each experiment. ‚ÄòOpe.‚Äô denotes ‚Äòoperation transfer‚Äô
                        in Experiment 3, while ‚ÄòLLM‚Äô refers to ‚ÄòLLM transfer‚Äô.
                      </md-block>
                      <!-- </div> -->

                      <div class="table-container">
                        <table>
                          <thead>
                            <tr>
                              <th rowspan="2">Experiment</th>
                              <th colspan="2">Data</th>
                            </tr>
                            <tr>
                              <th>HWT/MGT</th>
                              <th>MixSet</th>
                            </tr>
                          </thead>
                          <tbody>
                            <tr>
                              <td>Q 1</td>
                              <td class="italic">10k</td>
                              <td class="italic">0</td>
                            </tr>
                            <tr>
                              <td>Q 2(a)</td>
                              <td class="italic">10k</td>
                              <td class="italic">3k</td>
                            </tr>
                            <tr>
                              <td>Q 2(b)</td>
                              <td class="italic">10k</td>
                              <td class="italic">3k</td>
                            </tr>
                            <tr>
                              <td>Q 3(Ope.)</td>
                              <td class="italic">1k</td>
                              <td class="italic">0.5k</td>
                            </tr>
                            <tr>
                              <td>Q 3(LLM)</td>
                              <td class="italic">5k</td>
                              <td class="italic">1.5k</td>
                            </tr>
                            <tr>
                              <td>Q 4</td>
                              <td class="italic">1k/4k/7k/10k</td>
                              <td class="italic">0/1.5k/3k</td>
                            </tr>
                          </tbody>
                        </table>
                      </div>
                    </div>

                  </div>
                </div>
        </div>




        <p><b>Question 1.</b> Based on <b>MixSet</b>, we evaluate current detectors to determine the classification preferences
          on mixtext, i.e., Does the detector tend to classify mixtext as MGT or HWT? We calculate the percentage of
          mixtext samples categorized to MGT in the experiment. For the DistilBERT detector and other metric-based
          detectors utilizing logistic regression models, we employ a training set comprising 10,000 pre-processed
          samples of both pure HWT and MGT. For other detectors, we use existing checkpoints or API and evaluate them in
          a zero-shot setting.</p>

        <p><b>Question 2(a).</b> Following Question 1, our inquiry is whether the detector can accurately classify
          mixtext as MGT after training on <b>MixSet</b>. We finetune detectors on pure HWT and MGT data and a train split set
          of our <b>MixSet</b> labeled as MGT.</p>

        <p><b>Question 2(b).</b> On the other hand, assuming that mixtext lies outside the distribution of HWT and MGT,
          we conduct a three-class classification task, treating mixtext as a new label. In this scenario, we adopt
          multi-label training for these detectors while keeping all other settings consistent.</p>

        <p><b>Question 3.</b> Transfer ability is crucial for detectors, our objective is to investigate the
          effectiveness of transferring across different subsets of <b>MixSet</b> and LLMs. We establish two transfer
          experiments to assess whether the transferability of current detection methods is closely linked to the
          training dataset, referred to as operation-generalization and LLM-generalization:</p>

        <ol>
          <li><b>Operation-generalization (3a).</b> We initially train our detectors on one <b>MixSet</b> subset operated by
            one of these operations, along with pure HWT and MGT datasets, and then proceed to transfer it to the
            subsets processed by other operations.</li>
          <li><b>LLM-generalization (3b)</b> In this experiment, we train detectors on GPT-generated texts and HWT,
            following which we evaluate the detectors on mixtext generated by GPT family and Llama2, respectively, to
            see whether there is a generalization gap between different LLMs.</li>
        </ol>

        <p><b>Question 4.</b> Empirically, incorporating more training data has been shown to enhance detection
          capabilities and robustness for generalization. To determine the relation between detectors‚Äô performance and
          the size of the training set, we follow <b>Question 2</b> and use varying sizes of training sets to retrain
          detectors.</p>


      </div>
    </div>
  </section>

  <section class="section" id="Empirical Result">
    <div class="container is-max-desktop">
      <div class="featurecard-container">
        <!-- Trustworthiness and Utility -->
        <h1 class="title">Empirical Results</h1>
        <div class="cover" id="contentCover">
                <div class="infoCard">
                  <div class="infoBody">
                    <div class="tabs is-centered example_lst">
                      <ul>
                        <li class="is-active"><a title="Overall (Ex1 & Ex2)">Overall (Ex1 & Ex2)</a></li>
                        <li><a title="Integrating MixText for Binary">Integrating MixText for Binary</a></li>
                        <li><a title="Ex3a">Ex3a</a></li>
                        <li><a title="Ex3b">Ex3b</a></li>
                        <li><a title="Ex4">Ex4</a></li>
                      </ul>

                    </div>
                    <script type="text/javascript">
                      document.querySelectorAll(".example_lst li").forEach(e => {
                        e.addEventListener("click", Click_1)
                      })

                      function Click_1(eve) {
                        const iTxt = eve.srcElement.innerText
                        for (let v of document.querySelectorAll(".example_lst a")) {
                          if (iTxt === v.innerText) {
                            v.parentElement.className = "is-active";
                          } else {
                            v.parentElement.className = "";
                          }
                        }
                        for (let block of document.getElementsByClassName('lib_examples')) {
                          block.style.display = (block.title === iTxt) ? 'block' : 'none';
                        }
                      }

                    </script>
                    <div title="Overall (Ex1 & Ex2)" class="lib_examples" id="BoardPanel1" style="display: block;">
                      <!-- <div class="content has-text-justified"> -->
                      <md-block>
                        F1 score of experiment 2 (a) and (b). Tok. stands for token level and Sen. stands for sentence
                        level.
                        We <u>underscore</u> the best-performing detector and <b>bold</b> the score greater than 0.8,
                        which
                        we consider as a baseline
                        threshold for detection.
                      </md-block>
                      <!-- </div> -->
                      <div class="table-container">
                        <table>
                          <thead>
                            <tr>
                              <th rowspan="3">Detection Method</th>
                              <th rowspan="3">Average</th>
                              <th colspan="8">AI-Revised</th>
                              <th colspan="4">Human-Revised</th>
                            </tr>
                            <tr>
                              <th colspan="2">Complete</th>
                              <th colspan="2">Rewrite</th>
                              <th colspan="2">Polish-Tok.</th>
                              <th colspan="2">Polish-Sen.</th>
                              <th colspan="2">Humanize</th>
                              <th rowspan="2">Adapt-Sen.</th>
                              <th rowspan="2">Adapt-Tok.</th>
                            </tr>
                            <tr>
                              <td>Llama2</td>
                              <td>GPT-4</td>
                              <td>Llama2</td>
                              <td>GPT-4</td>
                              <td>Llama2</td>
                              <td>GPT-4</td>
                              <td>Llama2</td>
                              <td>GPT-4</td>
                              <td>Llama2</td>
                              <td>GPT-4</td>
                            </tr>
                          </thead>
                          <tbody>

                            <tr class="bold">
                              <td colspan="12"><b>Experiment 2 (a): Binary Classification</b></td>
                            </tr>
                            <tr>
                              <td>log-rank</td>
                              <td>0.615</td>
                              <td>0.695</td>
                              <td>0.686</td>
                              <td>0.637</td>
                              <td>0.479</td>
                              <td>0.617</td>
                              <td>0.606</td>
                              <td>0.647</td>
                              <td>0.595</td>
                              <td>0.617</td>
                              <td>0.454</td>
                              <td>0.676</td>
                              <td>0.667</td>
                            </tr>
                            <tr>
                              <td>log likelihood</td>
                              <td>0.624</td>
                              <td>0.695</td>
                              <td>0.695</td>
                              <td>0.637</td>
                              <td>0.492</td>
                              <td>0.657</td>
                              <td>0.627</td>
                              <td>0.657</td>
                              <td>0.657</td>
                              <td>0.657</td>
                              <td>0.386</td>
                              <td>0.676</td>
                              <td>0.667</td>
                            </tr>
                            <tr>
                              <td>GLTR</td>
                              <td>0.588</td>
                              <td>0.686</td>
                              <td>0.647</td>
                              <td>0.606</td>
                              <td>0.441</td>
                              <td>0.574</td>
                              <td>0.585</td>
                              <td>0.637</td>
                              <td>0.540</td>
                              <td>0.617</td>
                              <td>0.400</td>
                              <td>0.657</td>
                              <td>0.667</td>
                            </tr>
                            <tr>
                              <td>DetectGPT</td>
                              <td>0.635</td>
                              <td>0.715</td>
                              <td>0.651</td>
                              <td>0.656</td>
                              <td>0.560</td>
                              <td>0.632</td>
                              <td>0.587</td>
                              <td>0.657</td>
                              <td>0.632</td>
                              <td>0.692</td>
                              <td>0.587</td>
                              <td>0.641</td>
                              <td>0.609</td>
                            </tr>
                            <tr>
                              <td>Entropy</td>
                              <td>0.648</td>
                              <td>0.690</td>
                              <td>0.671</td>
                              <td>0.681</td>
                              <td>0.613</td>
                              <td>0.681</td>
                              <td>0.671</td>
                              <td>0.681</td>
                              <td>0.671</td>
                              <td>0.623</td>
                              <td>0.430</td>
                              <td>0.681</td>
                              <td>0.681</td>
                            </tr>
                            <tr>
                              <td>Openai Classifier</td>
                              <td>0.209</td>
                              <td>0.171</td>
                              <td>0.359</td>
                              <td>0.031</td>
                              <td>0.197</td>
                              <td>0.145</td>
                              <td>0.270</td>
                              <td>0.247</td>
                              <td>0.439</td>
                              <td>0.247</td>
                              <td>0.316</td>
                              <td>0.000</td>
                              <td>0.090</td>
                            </tr>
                            <tr>
                              <td>ChatGPT Detector</td>
                              <td>0.660</td>
                              <td>0.705</td>
                              <td>0.696</td>
                              <td>0.676</td>
                              <td>0.583</td>
                              <td>0.676</td>
                              <td>0.647</td>
                              <td>0.647</td>
                              <td>0.594</td>
                              <td>0.667</td>
                              <td>0.615</td>
                              <td>0.705</td>
                              <td>0.705</td>
                            </tr>
                            <tr class="bold">
                              <td>Radar</td>
                              <td><strong><u>0.876</u></strong></td>
                              <td><strong><u>0.867</u></strong></td>
                              <td><strong><u>0.877</u></strong></td>
                              <td><strong><u>0.877</u></strong></td>
                              <td><strong><u>0.877</u></strong></td>
                              <td><strong><u>0.877</u></strong></td>
                              <td><strong><u>0.877</u></strong></td>
                              <td><strong><u>0.877</u></strong></td>
                              <td><strong><u>0.877</u></strong></td>
                              <td><strong><u>0.877</u></strong></td>
                              <td><strong><u>0.877</u></strong></td>
                              <td><strong><u>0.877</u></strong></td>
                              <td><strong><u>0.877</u></strong></td>
                            </tr>
                            <tr>
                              <td>GPT-sentinel</td>
                              <td>0.713</td>
                              <td>0.714</td>
                              <td>0.714</td>
                              <td>0.714</td>
                              <td>0.714</td>
                              <td>0.714</td>
                              <td>0.714</td>
                              <td>0.714</td>
                              <td>0.714</td>
                              <td>0.714</td>
                              <td>0.696</td>
                              <td>0.714</td>
                              <td>0.714</td>
                            </tr>
                            <tr>
                              <td>Distillbert</td>
                              <td>0.664</td>
                              <td>0.667</td>
                              <td>0.667</td>
                              <td>0.667</td>
                              <td>0.667</td>
                              <td>0.667</td>
                              <td>0.667</td>
                              <td>0.667</td>
                              <td>0.667</td>
                              <td>0.667</td>
                              <td>0.639</td>
                              <td>0.667</td>
                              <td>0.667</td>
                            </tr>
                            <tr class="bold">
                              <td colspan="12"><b>Experiment 2 (b): Three-class Classification</b></td>
                            </tr>
                            <tr>
                              <td>DetectGPT</td>
                              <td>0.255</td>
                              <td>0.276</td>
                              <td>0.210</td>
                              <td>0.295</td>
                              <td>0.278</td>
                              <td>0.283</td>
                              <td>0.234</td>
                              <td>0.271</td>
                              <td>0.237</td>
                              <td>0.280</td>
                              <td>0.222</td>
                              <td>0.233</td>
                              <td>0.235</td>
                            </tr>
                            <tr>
                              <td>ChatGPT Detector</td>
                              <td>0.304</td>
                              <td>0.288</td>
                              <td>0.346</td>
                              <td>0.283</td>
                              <td>0.288</td>
                              <td>0.395</td>
                              <td>0.341</td>
                              <td>0.265</td>
                              <td>0.328</td>
                              <td>0.267</td>
                              <td>0.317</td>
                              <td>0.253</td>
                              <td>0.273</td>
                            </tr>
                            <tr class="bold">
                              <td>Radar</td>
                              <td><u>0.775</u></td>
                              <td><strong><u></u>0.804</td>
                              <td><strong><u></u>0.842</td>
                              <td><u>0.797</u></td>
                              <td><strong><u>0.837</u></strong></td>
                              <td><strong><u>0.831</u></strong></td>
                              <td><strong><u>0.820</u></strong></td>
                              <td><strong><u>0.815</u></strong></td>
                              <td><strong><u>0.837</u></strong></td>
                              <td><strong><u>0.884</u></strong></td>
                              <td><strong><u>0.889</u></strong></td>
                              <td><u>0.510</u></td>
                              <td><u>0.429</u></td>
                            </tr>
                            <tr>
                              <td>Distillbert</td>
                              <td>0.261</td>
                              <td>0.267</td>
                              <td>0.333</td>
                              <td>0.319</td>
                              <td>0.329</td>
                              <td>0.294</td>
                              <td>0.309</td>
                              <td>0.294</td>
                              <td>0.329</td>
                              <td>0.309</td>
                              <td>0.342</td>
                              <td>0.000</td>
                              <td>0.010</td>
                            </tr>
                          </tbody>
                        </table>
                      </div>

                    </div>

                    <div title="Integrating MixText for Binary" class="lib_examples" id="BoardPanel2"
                      style="display: none;">
                      <!-- <div class="content has-text-justified"> -->
                      <md-block>
                        The detection capabilities on pure HWT and
                        MGT, comparing performances with (w.) and without
                        (w.o.) MixSet labeling MGT during the training process,
                        with the better one <u>underscored</u>.
                      </md-block>
                      <!-- </div> -->

                      <div class="table-container">
                        <table>
                          <thead>
                            <tr>
                              <th rowspan="2">Detector</th>
                              <th colspan="2">F1</th>
                              <th colspan="2">AUC</th>
                            </tr>
                            <tr>
                              <th>w.o.</th>
                              <th>w.</th>
                              <th>w.o.</th>
                              <th>w.</th>
                            </tr>
                          </thead>
                          <tbody>
                            <tr>
                              <td>log-rank</td>
                              <td><u>0.830</u></td>
                              <td>0.821</td>
                              <td>0.922</td>
                              <td>0.922</td>
                            </tr>
                            <tr>
                              <td>log likelihood</td>
                              <td><u>0.845</u></td>
                              <td>0.834</td>
                              <td>0.931</td>
                              <td>0.931</td>
                            </tr>
                            <tr>
                              <td>GLTR</td>
                              <td><u>0.831</u></td>
                              <td>0.818</td>
                              <td>0.920</td>
                              <td>0.920</td>
                            </tr>
                            <tr>
                              <td>DetectGPT</td>
                              <td><u>0.746</u></td>
                              <td>0.725</td>
                              <td>0.820</td>
                              <td>0.820</td>
                            </tr>
                            <tr>
                              <td>Entropy</td>
                              <td>0.770</td>
                              <td>0.770</td>
                              <td>0.859</td>
                              <td>0.859</td>
                            </tr>
                            <tr class="bold">
                              <td>ChatGPT Det.</td>
                              <td>0.881</td>
                              <td><u>0.896</u></td>
                              <td>0.954</td>
                              <td><u>0.979</u></td>
                            </tr>
                            <tr>
                              <td>Radar</td>
                              <td>0.997</td>
                              <td>0.997</td>
                              <td>1.000</td>
                              <td>1.000</td>
                            </tr>
                            <tr>
                              <td>GPT-sentinel</td>
                              <td><u>0.988</u></td>
                              <td>0.982</td>
                              <td><u>1.000</u></td>
                              <td>0.999</td>
                            </tr>
                            <tr>
                              <td>Distillbert</td>
                              <td><u>0.996</u></td>
                              <td>0.984</td>
                              <td>1.000</td>
                              <td>1.000</td>
                            </tr>
                          </tbody>
                        </table>
                      </div>
                    </div>

                    <div title="Ex3a" class="lib_examples" id="BoardPanel3" style="display: none;">

                      <!-- <div class="content has-text-justified"> -->
                      <md-block>
                        Result of LLM-transfer experiments. Although
                        we retrain our detector on texts generated by GPT-4, it
                        shows convincing generalization ability to Llama2.
                      </md-block>
                      <!-- </div> -->

                      <div class="table-container">
                        <table>
                          <thead>
                            <tr>
                              <th rowspan="2">Method</th>
                              <th colspan="2">w.o MixSet</th>
                              <th colspan="2">w. MixSet</th>
                            </tr>
                            <tr>
                              <th>Llama2</th>
                              <th>GPT-4</th>
                              <th>Llama2</th>
                              <th>GPT-4</th>
                            </tr>
                          </thead>
                          <tbody>
                            <tr>
                              <td>GPT-sentinel</td>
                              <td><strong>0.813</strong></td>
                              <td><u>0.739</u></td>
                              <td><strong>0.972</strong></td>
                              <td><strong>0.971</strong></td>
                            </tr>
                            <tr>
                              <td>Radar</td>
                              <td><strong><u>0.834</u></strong></td>
                              <td>0.729</td>
                              <td><strong><u>0.997</u></strong></td>
                              <td><strong><u>1.000</u></strong></td>
                            </tr>
                            <tr>
                              <td>ChatGPT Det.</td>
                              <td>0.664</td>
                              <td>0.445</td>
                              <td>0.681</td>
                              <td>0.480</td>
                            </tr>
                            <tr>
                              <td>Distillbert</td>
                              <td>0.687</td>
                              <td>0.638</td>
                              <td>0.673</td>
                              <td>0.698</td>
                            </tr>
                          </tbody>
                        </table>
                      </div>
                    </div>

                    <div title="Ex3b" class="lib_examples" id="BoardPanel4" style="display: none;">

                      <!-- <div class="content has-text-justified"> -->
                      <md-block>
                        The AUC Heatmap of GPT-sentinel in Operation Transfer Experiment (Ex3a).
                      </md-block>
                      <!-- </div> -->

                      <img src="img/llm-coauthor-transfer.png" width="99%" alt="llm-coauthor transfer"
                        class="responsive-image">
                    </div>

                    <div title="Ex4" class="lib_examples" id="BoardPanel4" style="display: none;">

                      <!-- <div class="content has-text-justified"> -->
                      <md-block>
                        Analysis of the F1-score performance of various detectors across differing quantities of mixtext
                        instances
                        from **MixSet**, as well as pure MGT and HWT.
                      </md-block>
                      <!-- </div> -->

                      <img src="img/llm-coauthor-ex4.png" width="99%" alt="llm-coauthor ex4" class="responsive-image">
                    </div>
                  </div>
                </div>
        </div>
        <div class="feature_1x1">
          <div class="featurecard">
            <h2>There is no obvious classification preference in
              current detectors on mixtext.</h2>
          </div>
          <div class="description">
            In other words, the
            detectors do not exhibit a strong tendency to classify mixtext as either HWT or MGT. As we can observe from
            Figure 2 and Table 10, it is evident that
            the MGT percentage of mixtexts is between MGT
            and HWT, indicating that the current detectors do
            not have a strong preference towards mixtext classification. This proves the success and effectiveness
            of our constructed **MixSet** in presenting mixed
            features of HWT and MGT, demonstrating the limitations of existing detectors in recognizing mixtext.
            When dealing with mixtext, the detectors treat it
            as an intermediate state between HWT and MGT.
            Most detectors exhibit inconsistent classification
            within a single subset, fluctuating between accuracies of 0.3 and 0.7, akin to random choice. In AIrevised
            scenarios, subsets, such as polished tokens
            or sentences, pose extreme detection challenges.
            Mainstream detectors generally perform poorly in
            these cases due to the subtle differences between
            mixtext and original text. Furthermore, texts
            generated by Llama2-70b are easier to detect than
            those by GPT-4, possibly due to GPT-4‚Äôs closer
            generative distribution to human writing.
          </div>
        </div>

        <!-- Alignment of LLMs -->
        <div class="feature_1x1">
          <div class="featurecard">
            <h2>Binary and Three-class Classification</h2>
          </div>
          <div class="description">
            <p>
              <b>Supervised binary classification yields profound
                results; however, three-classes classification encounters significant challenges when applied to
                mixtext scenarios except Radar.</b>
              Retrained model-based detectors outperform metric-based methods in both binary and
              three-class classification tasks. Notably, Radar
              ranks first in our results, achieving a significant
              lead over other detectors. We suppose that this superior performance can be attributed to its
              encoder-decoder architecture, which boasts 7 billion trainable parameters, substantially more than its
              counterparts. We also examined the impact of retraining
              on **MixSet** on MGT detection performance. There was a slight decrease in the
              F1 score, while the AUC metric remained largely
              unaffected. Notably, post-retraining, the detector
              acquired the capability to identify mixtext‚Äîan advancement deemed highly valuable. This ability
              to detect mixtext, despite a minor trade-off in F1
              score for MGT detection, represents a significant
              step forward, suggesting a promising direction for enhancing detector versatility and applicability in
              varied contexts.
              In the three-class classification task, detectors
              based on LLMs, particularly the Radar detector, significantly outperformed those utilizing the BERT
              model. The BERT-based detectors‚Äô performance
              was markedly poor, akin to random guessing, with
              some models even underperforming a random baseline. This stark contrast underscores the efficacy of
              LLMs in capturing nuanced distinctions, as demonstrated in tasks like Mixtext. The superior performance of
              LLM-based Radar detectors lays a solid
              foundation for future explorations and applications
              in fine-grained classification tasks.
            </p>
          </div>
        </div>

        <!-- Performance Gap in Trustworthiness -->
        <div class="feature_1x1">
          <div class="featurecard">
            <h2>Current detectors struggle to generalize across
              different revised operation subsets of MixSet
              and generative models.</h2>
          </div>
          <div class="description">
            <p>
              Significant variability is observed in
              the transfer capabilities of three different detectors.
              Additionally, training on texts generated by different revised operations results in different transfer
              abilities for these detectors. Overall, Radar exhibits the most robust transfer capability among the
              four model-based detectors, achieving an overall
              classification accuracy exceeding 0.9, followed by GPT-sentinel, DistillBert, and finally, the ChatGPT
              Detector. Among various operations, ‚ÄòHumanize‚Äô
              exhibits the poorest transfer performance in almost
              all scenarios. Additionally, other operations also
              experience significant declines when dealing with
              ‚ÄòHumanize‚Äô mixtexts. This suggests that ‚ÄòHumanize‚Äô falls outside the current detectors‚Äô distribution
              of MGT, a gap that could be addressed by retraining on these specific cases. It is also
              noteworthy that texts generated by Llama2-70b
              demonstrate stronger transfer abilities than those generated by GPT4.
            </p>
          </div>
        </div>


        <!-- Transparency in Trustworthiness -->
        <div class="feature_1x1">

          <div class="featurecard">
            <h2>Increasing the number of mixtext samples in the
              training set effectively enhances the success rate
              of mixtext detection.</h2>
          </div>
          <div class="description">
            <p>
              However, adding pure text
              samples does not yield significant improvements
              and may even have a negative impact on detector
              performance, especially for metric-based methods.
              This may be attributed to subtle distribution shifts
              between mixtext and pure text. The current detector
              still faces significant challenges in capturing these
              subtle shifts. For mixtext scenarios, a more powerful and fine-grained detection method is needed.</p>

          </div>
        </div>

      </div>
    </div>
  </section>


  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h1 class="title">BibTeX</h1>
      <pre><code>@inproceedings{zhang-etal-2024-llm,
        title = "{LLM}-as-a-Coauthor: Can Mixed Human-Written and Machine-Generated Text Be Detected?",
        author = "Zhang, Qihui  and
          Gao, Chujie  and
          Chen, Dongping  and
          Huang, Yue  and
          Huang, Yixin  and
          Sun, Zhenyang  and
          Zhang, Shilin  and
          Li, Weiye  and
          Fu, Zhengyan  and
          Wan, Yao  and
          Sun, Lichao",
        year = "2024",
        url = "https://aclanthology.org/2024.findings-naacl.29"}
      </code></pre>
    </div>
  </section>
  <div class="content">
    <div id="supportContainer">
      <h1 class="supportTitle">LLM-as-a-Coauthor Team</h1>
      <br>

      <div id="logoContainer">
        <img src="img/logos/HUST.png" alt="School 1" class="schoolLogo">
        <img src="img/logos/ND.png" alt="School 2" class="schoolLogo">
        <img src="img/logos/IPDP.png" alt="School 3" class="schoolLogo">
        <img src="img/logos/Lehigh-University-logo.png" alt="School 4" class="schoolLogo">
        <!-- <img src="img/logos/Microsoft.png" alt="School 4" class="schoolLogo"> -->

      </div>


    </div>
  </div>
  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
            <p>
              This means you are free to borrow the <a href="https://github.com/nerfies/nerfies.github.io">source
                code</a> of this website,
              we just ask that you link back to this page in the footer.

            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>